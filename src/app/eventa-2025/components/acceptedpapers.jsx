const AcceptedPapers = () => {
    return (
        <div className="text-justify">
            <td className="border px-3 py-2 font-bold">ACM Multimedia 2025 Proceedings:</td>
            <ol className="list-disc list-inside space-y-2 mt-2 mb-8 ml-4">
                <li>Cerebro Team, "ENRIC: EveNt-AwaRe Captioning with Image Retrieval via UnCertainty-Guided Re-ranking and Semantic Ensemble Reasoning". [<a href="https://drive.google.com/file/d/11h6cBv8Gi8cvXynqsflWT8aYl_Lmm_oB/view?usp=drive_link" target="_blank" rel="noopener noreferrer" className="text-blue-600 hover:underline">PDF</a>] </li>
                <li>SodaBread Team, "ReCap: Event-Aware Image Captioning with Article Retrieval and Semantic Gaussian Normalization". [<a href="https://drive.google.com/file/d/112BpFQxf0boqeqjKvWA0UoPLluF6KCW1/view?usp=drive_link" target="_blank" rel="noopener noreferrer" className="text-blue-600 hover:underline">PDF</a>] </li>
                <li>NoResources Team, "EVENT-Retriever: Event-Aware Multimodal Image Retrieval for Realistic Captions". [<a href="https://drive.google.com/file/d/1WY0WSVxVgkSkERsFiBbH20XZfciw2aJ9/view?usp=drive_link" target="_blank" rel="noopener noreferrer" className="text-blue-600 hover:underline">PDF</a>] </li>
            </ol>
            <br/>
            <td className="border px-3 py-2 font-bold">Unachieved Papers:</td>
            <ol className="list-disc list-inside space-y-2 mt-2 mb-8 ml-4">
                <li>Re:zero Slavery Team, "Beyond Vision: Contextually Enriched Image Captioning with Multi-Modal Retrieval". [<a href="https://drive.google.com/file/d/1_-0QwLfkggtv_6t4AWOEB34_ba6S5AiL/view?usp=drive_link" target="_blank" rel="noopener noreferrer" className="text-blue-600 hover:underline">PDF</a>] </li>
                <li>ITxTK9 Team, "ZSE-Cap: A Zero-Shot Ensemble for Image Retrieval and Prompt-Guided Captioning". [<a href="https://drive.google.com/file/d/1yo9ZlnXDU2B1qLcVF2IuMVPe9G8sxXqS/view?usp=drive_link" target="_blank" rel="noopener noreferrer" className="text-blue-600 hover:underline">PDF</a>] </li>
                <li>HCMUS-NoName Team, "Hierarchical Multi-Modal Retrieval for Knowledge-Grounded News Image Captioning". [<a href="https://drive.google.com/file/d/1nA-RsByqLOwolnjnHy74uV7M_ppe5A1q/view?usp=drive_link" target="_blank" rel="noopener noreferrer" className="text-blue-600 hover:underline">PDF</a>] </li>
                <li>23Trinitrotoluen Team, "A Hybrid Dense-Sparse Multi-Stage Re-ranking Framework for Event-Based Image Retrieval". [<a href="https://drive.google.com/file/d/1z1emGFeWblzfZNHfj7KFqWS6QIZnkWvt/view?usp=drive_link" target="_blank" rel="noopener noreferrer" className="text-blue-600 hover:underline">PDF</a>] </li>
                <li>LastSong Team, "Hierarchical Article-to-Image: Leveraging Multi-Granularity Text Representations for Article Ranking and Text-Visual Similarity for Image Retrieval". [<a href="https://drive.google.com/file/d/17OOxauy6wzqgb4y7l7JN0d2w0CyspBEO/view?usp=drive_link" target="_blank" rel="noopener noreferrer" className="text-blue-600 hover:underline">PDF</a>] </li>
                <li>Sharingan Retrievers Team, "Leveraging Lightweight Entity Extraction for Scalable Event-Based Image Retrieval". [<a href="https://drive.google.com/file/d/1cXW2PCxcmrrJnqCtsvv0cDAWGuMkiBPOV/view?usp=drive_link" target="_blank" rel="noopener noreferrer" className="text-blue-600 hover:underline">PDF</a>] </li>
                <li>ZJH-FDU Team, "A Pretrained Model-Based Pipeline for Event-Driven News-to-Image Retrieval". [<a href="https://drive.google.com/file/d/165SqUWwJq2t29s_3BrWm-nSkefMa3f9h/view?usp=drive_link" target="_blank" rel="noopener noreferrer" className="text-blue-600 hover:underline">PDF</a>] </li>
            </ol>

        </div>
    )
}
export default AcceptedPapers;
